#!/usr/bin/env python3
"""
VeilleurIA v2.3 â€” Agent de veille IA agentique avec hub Notion
==============================================================

Skill Claude natif â€” API Anthropic (claude-sonnet-4-6).

NOUVEAUTÃ‰S v2.3 vs v2.2 :

    â‘  Partie 3 â€” Skills Claude
    â‘¡ Reddit RSS â€” 3 subreddits (r/LocalLLaMA, r/AIAgents, r/MachineLearning)
    â‘¢ Hub Notion â€” 4 destinations automatiques
    â‘£ Telegram â€” notification courte avec lien Notion

Analogie TP :
    v2.3 = topographe qui dÃ©pose le rapport complet dans le classeur,
           extrait les cotes critiques, et envoie juste un SMS "rapport dispo".

Architecture v2.3 :
    Cron 19h45 â†’ [1] RSS â†’ [2] web_search â†’ [3] critique â†’ [4] synthÃ¨se
              â†’ [5] redistribution Notion â†’ [6] Telegram

Usage :
    python agent_veilleur_ia_v2_3.py              # Production complÃ¨te
    python agent_veilleur_ia_v2_3.py --test       # Thinking off, rapide
    python agent_veilleur_ia_v2_3.py --dry-run    # Rapport terminal uniquement
    python agent_veilleur_ia_v2_3.py --feedback like "Super section Skills Claude"

Requirements :
    pip install anthropic feedparser python-telegram-bot python-dotenv tenacity notion-client

Author : Vlad / SRC â€” Projet Agentic IA 2026
Version : 2.3.0
"""

import argparse
import asyncio
import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

import feedparser
from anthropic import Anthropic
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential

# â”€â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("veilleur_ia.log", encoding="utf-8"),
    ],
)
logger = logging.getLogger(__name__)

load_dotenv()

# â”€â”€â”€ ModÃ¨les â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_SYNTHESIS = "claude-sonnet-4-6"
MODEL_COLLECT   = "claude-haiku-4-5-20251001"

THINKING_BUDGET = 3000
FEEDBACK_FILE   = Path("feedback_history.json")
LOCK_FILE       = Path("/tmp/veilleur_ia.lock")
FEEDBACK_WINDOW = 14

# â”€â”€â”€ Sources RSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RSS_AGENTIQUE = [
    {"name": "Anthropic Blog",    "url": "https://www.anthropic.com/rss.xml",                      "focus": "agentique"},
    {"name": "LangChain Blog",    "url": "https://blog.langchain.dev/rss/",                         "focus": "agentique"},
    {"name": "Hugging Face",      "url": "https://huggingface.co/papers.rss",                       "focus": "agentique"},
    {"name": "The Rundown AI",    "url": "https://www.therundown.ai/feed",                          "focus": "agentique"},
    {"name": "Latent Space",      "url": "https://www.latent.space/feed",                           "focus": "agentique"},
    {"name": "r/LocalLLaMA",      "url": "https://www.reddit.com/r/LocalLLaMA/.rss",                "focus": "agentique"},
    {"name": "r/AIAgents",        "url": "https://www.reddit.com/r/AIAgents/.rss",                  "focus": "agentique"},
    {"name": "r/MachineLearning", "url": "https://www.reddit.com/r/MachineLearning/.rss",           "focus": "agentique"},
]

RSS_OPENCLAW = [
    {"name": "OpenClaw Releases",    "url": "https://github.com/openclaw/openclaw/releases.atom",    "focus": "openclaw"},
    {"name": "OpenClaw Discussions", "url": "https://github.com/openclaw/openclaw/discussions.atom", "focus": "openclaw"},
]

RSS_SKILLS_CLAUDE = [
    {"name": "Anthropic Blog", "url": "https://www.anthropic.com/rss.xml",      "focus": "skills"},
    {"name": "r/ClaudeAI",     "url": "https://www.reddit.com/r/ClaudeAI/.rss", "focus": "skills"},
]

# â”€â”€â”€ RequÃªtes web_search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
QUERIES_AGENTIQUE = [
    "agentic AI framework news today 2026",
    "LangGraph CrewAI AutoGen new release 2026",
    "Claude MCP A2A protocol update latest",
    "ArXiv agentic AI multi-agent paper today 2026",
    "LLM agent benchmark comparison 2026",
    "AI agent security vulnerability CVE 2026",
]

QUERIES_OPENCLAW = [
    "OpenClaw agent framework update 2026",
    "OpenClaw community discussion workflow hack",
    "ClawHub AgentSkill new release security 2026",
]

QUERIES_SKILLS_CLAUDE = [
    "Claude skill MCP tool new release 2026",
    "Anthropic Claude API new feature update 2026",
    "Claude skill builder best practices production 2026",
]

# â”€â”€â”€ IDs Notion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NOTION_DB_RAPPORTS      = os.getenv("NOTION_DB_RAPPORTS_ID", "")
NOTION_DB_PEDAGOGIE     = os.getenv("NOTION_DB_PEDAGOGIE_ID", "")
NOTION_DB_SYSTEME       = os.getenv("NOTION_DB_SYSTEME_ID", "")
NOTION_DB_MISE_EN_PLACE = os.getenv("NOTION_DB_MISE_EN_PLACE_ID", "")


# â”€â”€â”€ Classe principale â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class VeilleurIA:
    """Agent de veille IA agentique v2.3 â€” Hub Notion + 3 parties."""

    def __init__(self, test_mode: bool = False, dry_run: bool = False) -> None:
        self._check_env()
        self.client    = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.test_mode = test_mode
        self.dry_run   = dry_run

        # Sonnet toujours pour la synthÃ¨se â€” Haiku ne suit pas les prompts longs
        self.synthesis_model = MODEL_SYNTHESIS
        self.collect_model   = MODEL_COLLECT
        self.use_thinking    = not test_mode  # Thinking off en test pour aller vite

        self.notion = self._init_notion()

        logger.info(
            f"ğŸš€ VeilleurIA v2.3 | {self.synthesis_model} | "
            f"Thinking: {self.use_thinking} | Notion: {'âœ…' if self.notion else 'âŒ'} | "
            f"Test: {test_mode} | DryRun: {dry_run}"
        )

    def _check_env(self) -> None:
        """VÃ©rifie les variables d'environnement obligatoires."""
        missing = [v for v in ["ANTHROPIC_API_KEY"] if not os.getenv(v)]
        if missing:
            raise EnvironmentError(f"âŒ Variables manquantes : {', '.join(missing)}")

    def _init_notion(self):
        """
        Initialise le client Notion si le token est disponible.

        Analogie TP : VÃ©rifier qu'on a bien le badge d'accÃ¨s au classeur.
        """
        token = os.getenv("NOTION_TOKEN")
        if not token:
            logger.warning("âš ï¸  NOTION_TOKEN absent â€” Notion dÃ©sactivÃ©")
            return None
        try:
            from notion_client import Client
            client = Client(auth=token)
            logger.info("  âœ… Client Notion initialisÃ©")
            return client
        except ImportError:
            logger.warning("âš ï¸  notion-client non installÃ© â†’ pip install notion-client")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸  Erreur init Notion : {e}")
            return None

    # â”€â”€â”€ Collecte RSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def collect_rss(self, sources: list[dict], max_hours: int = 24) -> list[dict]:
        """
        Collecte les entrÃ©es RSS des derniÃ¨res N heures.

        Analogie TP : Ramasser les feuilles de pointage depuis hier matin.
        """
        entries = []
        cutoff  = datetime.now() - timedelta(hours=max_hours)

        for source in sources:
            try:
                logger.info(f"  ğŸ“¡ {source['name']}")
                feed = feedparser.parse(
                    source["url"],
                    request_headers={"User-Agent": "VeilleurIA/2.3 (veille IA agentique)"},
                )
                for entry in feed.entries[:8]:
                    pub = None
                    if hasattr(entry, "published_parsed") and entry.published_parsed:
                        pub = datetime(*entry.published_parsed[:6])
                    if pub and pub < cutoff:
                        continue
                    entries.append({
                        "source":    source["name"],
                        "focus":     source["focus"],
                        "title":     entry.get("title", "Sans titre"),
                        "link":      entry.get("link", ""),
                        "summary":   entry.get("summary", "")[:400],
                        "published": pub.isoformat() if pub else "Inconnu",
                    })
            except Exception as e:
                logger.warning(f"  âš ï¸  RSS {source['name']} : {e}")

        logger.info(f"  âœ… {len(entries)} entrÃ©es collectÃ©es")
        return entries

    # â”€â”€â”€ RÃ©sumÃ© RSS Haiku â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def summarize_rss(self, entries: list[dict], focus: str) -> str:
        """
        RÃ©sume les entrÃ©es RSS brutes via Haiku.

        Analogie TP : L'ouvrier qui retranscrit les cotes brutes â€” travail mÃ©canique.
        """
        if not entries:
            return f"Aucune entrÃ©e RSS rÃ©cente pour {focus}."

        formatted = "\n".join(
            f"- [{e['source']}] {e['title']}\n  {e['summary']}"
            for e in entries[:12]
        )
        response = self.client.messages.create(
            model=self.collect_model,
            max_tokens=600,
            messages=[{"role": "user", "content":
                f"RÃ©sume en 3-5 points clÃ©s factuels les infos RSS {focus} :\n\n{formatted}"
            }],
        )
        return response.content[0].text

    # â”€â”€â”€ Recherche web Sonnet 4.6 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def search_web(self, queries: list[str], focus: str) -> str:
        """
        Recherche web via Sonnet 4.6 + outil web_search natif.

        Analogie TP : Le topographe senior avec sa station totale.
        """
        logger.info(f"  ğŸ” {len(queries)} requÃªtes web ({focus})")
        queries_fmt = "\n".join(f"{i+1}. {q}" for i, q in enumerate(queries))
        response = self.client.messages.create(
            model=self.synthesis_model,
            max_tokens=2500,
            tools=[{"type": "web_search_20250305", "name": "web_search"}],
            messages=[{"role": "user", "content":
                f"""Expert IA agentique, veille quotidienne {focus} â€” {datetime.now().strftime('%d/%m/%Y')}.
Lance ces recherches et synthÃ©tise les rÃ©sultats factuellement :
{queries_fmt}
Identifie : annonces majeures, releases, discussions importantes, sources (URLs)."""
            }],
        )
        return "".join(b.text for b in response.content if hasattr(b, "text")) or "Aucun rÃ©sultat."

    # â”€â”€â”€ Passe critique Haiku â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def critical_filter(self, rss: str, web: str, focus: str) -> str:
        """
        Filtre Haiku : extrait le top 5 informations les plus importantes.

        Analogie TP : L'assistant qui trie 50 relevÃ©s et garde les 5 cotes critiques.
        """
        logger.info(f"  ğŸ¯ Passe critique ({focus})")
        response = self.client.messages.create(
            model=self.collect_model,
            max_tokens=500,
            messages=[{"role": "user", "content":
                f"""Ã‰diteur expert IA {focus}. Identifie les 5 infos les PLUS IMPORTANTES du jour.

RSS : {rss}
WEB : {web}

CritÃ¨res : nouveautÃ© rÃ©elle, impact praticien IA, actionnable, pas de doublon.
Format : 1. [SOURCE] Titre â€” impact en une phrase (5 max, triÃ©s par importance)"""
            }],
        )
        return response.content[0].text

    # â”€â”€â”€ Chargement feedback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def load_feedback(self) -> str:
        """Charge le contexte feedback des 14 derniers jours."""
        if not FEEDBACK_FILE.exists():
            return "Aucun feedback historique."
        try:
            with open(FEEDBACK_FILE, encoding="utf-8") as f:
                all_fb = json.load(f)
            cutoff = datetime.now() - timedelta(days=FEEDBACK_WINDOW)
            recent = [fb for fb in all_fb if datetime.fromisoformat(fb["date"]) > cutoff]
            if not recent:
                return "Aucun feedback rÃ©cent."
            likes    = [fb["note"] for fb in recent if fb["type"] == "like"]
            dislikes = [fb["note"] for fb in recent if fb["type"] == "dislike"]
            notes    = [fb["note"] for fb in recent if fb["type"] == "note"]
            return f"""FEEDBACK 14 DERNIERS JOURS ({len(recent)} retours) :
âœ… ApprÃ©ciÃ© : {chr(10).join(f'- {l}' for l in likes[-5:]) if likes else '- Aucun encore'}
âŒ Pas plu : {chr(10).join(f'- {d}' for d in dislikes[-5:]) if dislikes else '- Aucun encore'}
ğŸ“ Notes : {chr(10).join(f'- {n}' for n in notes[-3:]) if notes else '- Aucune encore'}
â†’ Adapte le rapport selon ces prÃ©fÃ©rences."""
        except Exception as e:
            logger.warning(f"âš ï¸  Feedback : {e}")
            return "Erreur chargement feedback."

    # â”€â”€â”€ SynthÃ¨se rapport Sonnet 4.6 + Extended Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def generate_report(
        self,
        filtered_agentique: str,
        filtered_openclaw:  str,
        filtered_skills:    str,
        feedback:           str,
    ) -> str:
        """
        GÃ©nÃ¨re le rapport complet via Sonnet 4.6 + Extended Thinking.

        Analogie TP :
            Le conducteur de travaux qui rÃ©flÃ©chit (Extended Thinking) puis rÃ©dige
            le compte-rendu maÃ®tre d'ouvrage d'une traite. Cible : 6000-7000 mots.
        """
        # FIX : today correctement indentÃ© dans la mÃ©thode
        today = datetime.now().strftime("%d/%m/%Y")

        prompt = f"""Tu es VeilleurIA v2.3, expert IA agentique. Rapport quotidien pour Vlad.

PROFIL : Conducteur de travaux TP â†’ reconversion ingÃ©nieur IA agentique.
CS50P validÃ© + 275p ML + stack 13 agents en prod. Praticien, pas thÃ©oricien.
OBJECTIF : Imaginer de TOUT NOUVEAUX agents from scratch. Ne relie PAS aux agents existants.

{feedback}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOP INFOS DU JOUR â€” {today}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ§  AGENTIQUE (top 5) : {filtered_agentique}
ğŸ¦ OPENCLAW (top 5)  : {filtered_openclaw}
ğŸ› ï¸  SKILLS CLAUDE (top 5) : {filtered_skills}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FORMAT RAPPORT â€” EXIGENCES STRICTES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GÃ©nÃ¨re EXACTEMENT ce format. Cible : 6000-7000 mots.

---
ğŸ¤– VEILLE IA AGENTIQUE â€” {today}
---

## ğŸ§  PARTIE 1 : AGENTIQUE GÃ‰NÃ‰RALE

### ğŸ“° Information (200-250 mots)
2-3 news majeures : faits + pourquoi important maintenant + impact concret pour Vlad.

### ğŸ“ PÃ©dagogie (400-500 mots)
**Concept** : dÃ©finition claire
**Analogie BTP** : cas concret chantier/TP
**MÃ©canisme** : comment Ã§a marche sous le capot
**Code** : bloc Python 15-25 lignes, commentaires PAR BLOC
**Nouvelle Application** : imagine un tout NOUVEL agent autonome basÃ© sur ce concept
**Ressources** : 1-2 liens concrets

### âš™ï¸ SystÃ¨me (500-600 mots)
**Architecture** : schÃ©ma ASCII si pertinent
**Code production-ready** : complet, commentÃ© par bloc, gestion erreurs
**Commandes exactes** : shell/CLI dans l'ordre
**ParamÃ¨tres critiques** : valeurs, piÃ¨ges, defaults dangereux
**Architecture Nouveau Projet** : structurer un NOUVEL agent de A Ã  Z avec ce snippet

### ğŸ”— Mise en place (200-300 mots)
**IdÃ©e de Nouvel Agent** : quel agent inÃ©dit prototyper demain
**3 Ã©tapes concrÃ¨tes** : numÃ©rotÃ©es, actionnables dÃ¨s demain
**Commande de test** : valider le POC

---

## ğŸ¦ PARTIE 2 : OPENCLAW

### ğŸ“° Information (200-250 mots)
Releases (numÃ©ro version exact), breaking changes, nouvelles features, CVE si applicable.

### ğŸ“ PÃ©dagogie (400-500 mots)
**Concept OpenClaw** : ce que c'est, pourquoi dans OpenClaw
**Analogie BTP** : OPC, sous-traitants, etc.
**MÃ©canisme** : agents.yaml, gateway, skills
**Config YAML** : bloc complet commentÃ© par bloc
**Cas d'usage inÃ©dit** : nouveau type d'agent Ã  construire avec ce composant
**Commande dÃ©ploiement** : commande exacte openclaw

### âš™ï¸ SystÃ¨me (500-600 mots)
**Config YAML complÃ¨te** : commentÃ©e par bloc
**Hack communautaire** : technique + contexte
**IntÃ©gration KVM1** : dÃ©ploiement sur le gateway Hostinger
**Snippet Python** : si applicable, production-ready
**Test validation** : commande avant push prod

### ğŸ”— Mise en place (200-300 mots)
**Nouvelle piste OpenClaw** : quel nouvel agent imaginer
**3 Ã©tapes** : actionnables dÃ¨s demain
**Commande de test** : validation concrÃ¨te

---

## ğŸ› ï¸ PARTIE 3 : SKILLS CLAUDE

### ğŸ“° Information (200-250 mots)
Nouveaux skills, mises Ã  jour MCP, Ã©volutions API Claude, discussions communautaires.

### ğŸ“ PÃ©dagogie (400-500 mots)
**Concept skill** : ce qu'est ce skill/feature, pourquoi il existe
**Analogie BTP** : connexion terrain TP
**MÃ©canisme** : comment Claude l'implÃ©mente (system prompt, tools, context)
**Exemple config** : YAML ou Python complet, commentÃ© par bloc
**Nouvelle Application** : quel agent innovant crÃ©er de zÃ©ro grÃ¢ce Ã  ce skill
**Ressources** : doc Anthropic, exemples GitHub

### âš™ï¸ SystÃ¨me (500-600 mots)
**Config complÃ¨te** : YAML ou Python, commentÃ©e par bloc
**ImplÃ©mentation** : intÃ©gration dans la conception d'un tout nouvel agent
**ParamÃ¨tres clÃ©s** : ce qui change vraiment la qualitÃ©
**Test validation** : vÃ©rifier que le skill fonctionne
**Optimisation coÃ»t** : model routing si applicable

### ğŸ”— Mise en place (200-300 mots)
**Inspiration Nouveau Skill** : quel nouveau skill dÃ©velopper
**3 Ã©tapes concrÃ¨tes** : numÃ©rotÃ©es, avec commandes si applicable
**Validation** : mesurer que le prototype fonctionne

---

## ğŸ’¡ INSIGHT DU JOUR (150-200 mots)
Connexion transversale non Ã©vidente entre les 3 parties.
Tendance de fond. Implication stratÃ©gique pour les futurs agents de Vlad.

---
ğŸ“Š Sources : [liste clÃ©s avec URLs]
â±ï¸ {datetime.now().strftime("%H:%M")} | VeilleurIA v2.3 | Sonnet 4.6 + Extended Thinking
---

RÃˆGLES ABSOLUES :
- Code commentÃ© PAR BLOC
- Analogies BTP systÃ©matiques dans toutes les sections PÃ©dagogie
- NE PAS adapter aux agents existants â€” idÃ©ation nouveaux agents uniquement
- Jamais inventer une info â€” absence > inexactitude"""

        params: dict = {
            "model":      self.synthesis_model,
            "max_tokens": 14000,
            "messages":   [{"role": "user", "content": prompt}],
        }
        if self.use_thinking:
            params["thinking"] = {"type": "enabled", "budget_tokens": THINKING_BUDGET}
            logger.info(f"  ğŸ§  Extended Thinking activÃ© ({THINKING_BUDGET} tokens budget)")

        response = self.client.messages.create(**params)

        # Extraire uniquement le texte final (pas les blocs thinking internes)
        report = "".join(
            b.text for b in response.content
            if hasattr(b, "type") and b.type == "text"
        )
        return report or "Erreur gÃ©nÃ©ration rapport."

    # â”€â”€â”€ Redistribution Notion via Haiku â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def extract_for_notion(self, report: str, section: str) -> str:
        """
        Extrait une section du rapport par string slicing direct â€” sans LLM.

        Analogie TP :
            Au lieu de demander Ã  un ouvrier de recopier les pages,
            on les dÃ©coupe directement au cutter. Plus rapide, aucune perte.

        Avantages vs extraction Haiku :
            - ZÃ©ro token consommÃ©
            - ZÃ©ro troncature possible â€” contenu garanti complet
            - InstantanÃ©
        """
        # Marqueurs de section correspondant aux titres gÃ©nÃ©rÃ©s par Sonnet
        section_markers = {
            "pedagogie":     "### ğŸ“ PÃ©dagogie",
            "systeme":       "### âš™ï¸ SystÃ¨me",
            "mise_en_place": "### ğŸ”— Mise en place",
        }

        # Tous les marqueurs de sous-section pour dÃ©limiter la fin d'une section
        all_subsection_markers = [
            "### ğŸ“° Information",
            "### ğŸ“ PÃ©dagogie",
            "### âš™ï¸ SystÃ¨me",
            "### ğŸ”— Mise en place",
            "## ğŸ§  PARTIE",
            "## ğŸ¦ PARTIE",
            "## ğŸ› ï¸ PARTIE",
            "## ğŸ’¡ INSIGHT",
        ]

        start_marker = section_markers[section]
        full_content = []
        partie_num   = 0
        search_from  = 0

        # Chercher toutes les occurrences du marqueur (une par partie)
        while True:
            start_idx = report.find(start_marker, search_from)
            if start_idx == -1:
                break

            partie_num += 1

            # Trouver la fin = prochain marqueur de sous-section
            end_idx = len(report)
            for marker in all_subsection_markers:
                pos = report.find(marker, start_idx + len(start_marker))
                if pos != -1 and pos < end_idx:
                    end_idx = pos

            section_content = report[start_idx:end_idx].strip()
            if section_content:
                full_content.append(f"## Partie {partie_num}\n\n{section_content}")

            search_from = start_idx + len(start_marker)

        if not full_content:
            logger.warning(f"  âš ï¸  Aucune section '{section}' trouvÃ©e dans le rapport")
            return "Section non trouvÃ©e dans le rapport."

        logger.info(f"  âœ‚ï¸  Extraction '{section}' : {len(full_content)} parties trouvÃ©es")
        return "\n\n---\n\n".join(full_content)

    # â”€â”€â”€ Parser Markdown â†’ blocs Notion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _fix_unclosed_code_blocks(self, text: str) -> str:
        """
        RÃ©pare les blocs de code non fermÃ©s dans le rapport Sonnet.

        Analogie TP :
            VÃ©rifier que chaque coffrage ouvert est bien refermÃ© avant
            de couler le bÃ©ton â€” sinon tout dÃ©borde.

        Sonnet gÃ©nÃ¨re parfois un ``` sans ``` fermant correspondant.
        Tout le texte suivant se retrouve aspirÃ© dans un bloc code gÃ©ant.
        Ce pre-processing compte les backticks et ferme les blocs orphelins.
        """
        lines   = text.split("\n")
        in_code = False
        result  = []

        for line in lines:
            if line.strip().startswith("```"):
                in_code = not in_code
            result.append(line)

        # Si on termine encore dans un bloc code â†’ ajouter le ``` fermant
        if in_code:
            result.append("```")
            logger.warning("  ğŸ”§ Bloc code non fermÃ© rÃ©parÃ© automatiquement")

        return "\n".join(result)

    def _parse_content_to_blocks(self, content: str) -> list:
        """
        Parse le contenu Markdown en blocs Notion ligne par ligne.

        Analogie TP : Trier bÃ©ton/ferraillage avant de ranger â€” pas de mÃ©lange.

        Pourquoi ligne par ligne et pas split('\\n\\n') :
            Les blocs ```code``` contiennent des sauts de ligne internes
            que le split naÃ¯f dÃ©coupe en morceaux inutilisables.
        """
        # RÃ©parer les blocs code non fermÃ©s avant de parser
        content = self._fix_unclosed_code_blocks(content)

        blocks = []
        lines  = content.split("\n")
        i      = 0

        while i < len(lines):
            line = lines[i]

            # â”€â”€ Bloc de code : accumulation jusqu'au ``` fermant â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if line.strip().startswith("```"):
                lang       = line.strip().replace("```", "").strip() or "python"
                code_lines = []
                i += 1
                while i < len(lines) and not lines[i].strip().startswith("```"):
                    # Sortir du bloc code si on rencontre un titre ## ou ###
                    # Ces marqueurs ne peuvent jamais apparaÃ®tre dans du vrai code
                    # On exclut # seul (commentaires Python) et --- (sÃ©parateurs bash)
                    if lines[i].startswith(("## ", "### ")):
                        logger.warning(f"  ğŸ”§ Titre dÃ©tectÃ© dans bloc code ligne {i} â€” fermeture forcÃ©e")
                        break
                    code_lines.append(lines[i])
                    i += 1
                code = "\n".join(code_lines).strip()
                if code:
                    valid_langs = ["python", "javascript", "bash", "yaml", "json", "markdown", "plain text"]
                    for chunk in [code[j:j+1990] for j in range(0, len(code), 1990)]:
                        blocks.append({
                            "object": "block", "type": "code",
                            "code": {
                                "rich_text": [{"type": "text", "text": {"content": chunk}}],
                                "language":  lang if lang in valid_langs else "plain text",
                            },
                        })
                # Saute le ``` fermant seulement s'il existe
                # Si EOF atteint = bloc non fermÃ© dans le rapport Sonnet
                if i < len(lines) and lines[i].strip().startswith("```"):
                    i += 1
                else:
                    logger.warning(f"  âš ï¸  Bloc code non fermÃ© (lang={lang}) â€” {len(code_lines)} lignes rÃ©cupÃ©rÃ©es quand mÃªme")
                continue

            # â”€â”€ Titre # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if line.startswith("# ") and not line.startswith("## "):
                blocks.append({
                    "object": "block", "type": "heading_1",
                    "heading_1": {"rich_text": [{"type": "text", "text": {"content": line[2:][:200]}}]},
                })
                i += 1; continue

            # â”€â”€ Titre ## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if line.startswith("## "):
                blocks.append({
                    "object": "block", "type": "heading_2",
                    "heading_2": {"rich_text": [{"type": "text", "text": {"content": line[3:][:200]}}]},
                })
                i += 1; continue

            # â”€â”€ Titre ### â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if line.startswith("### "):
                blocks.append({
                    "object": "block", "type": "heading_3",
                    "heading_3": {"rich_text": [{"type": "text", "text": {"content": line[4:][:200]}}]},
                })
                i += 1; continue

            # â”€â”€ Ligne vide â†’ skip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if not line.strip():
                i += 1; continue

            # â”€â”€ Paragraphe standard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            for chunk in [line[j:j+1990] for j in range(0, len(line), 1990)]:
                blocks.append({
                    "object": "block", "type": "paragraph",
                    "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]},
                })
            i += 1

        return blocks

    # â”€â”€â”€ CrÃ©ation page Notion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def create_notion_page(
        self,
        database_id: str,
        title:       str,
        content:     str,
        categorie:   Optional[str] = None,
    ) -> Optional[str]:
        """
        CrÃ©e une sous-page dans une page Notion parente.
        Envoie le contenu par batch de 100 blocs (limite API Notion).

        Analogie TP :
            Livrer le bÃ©ton en plusieurs camions toupie â€”
            Notion ne peut recevoir que 100 blocs par livraison.
        """
        if not self.notion or not database_id:
            logger.warning(f"  âš ï¸  Notion non disponible pour '{title}'")
            return None

        try:
            # Parser le Markdown en blocs Notion
            all_blocks = self._parse_content_to_blocks(content)

            # CrÃ©ation initiale avec les 100 premiers blocs
            page    = self.notion.pages.create(
                parent     = {"page_id": database_id},
                properties = {"title": {"title": [{"text": {"content": title}}]}},
                children   = all_blocks[:100],
            )
            page_id = page.get("id", "")
            url     = page.get("url", "")

            # Append des blocs restants par batch de 100
            # Notion limite Ã  100 blocs par appel â€” on boucle avec retry explicite
            remaining  = all_blocks[100:]
            batch_num  = 1
            while remaining:
                batch = remaining[:100]
                for attempt in range(3):  # 3 tentatives par batch
                    try:
                        self.notion.blocks.children.append(
                            block_id = page_id,
                            children = batch,
                        )
                        logger.info(f"    ğŸ“¦ Batch {batch_num} envoyÃ© ({len(batch)} blocs)")
                        break
                    except Exception as batch_err:
                        logger.warning(f"    âš ï¸  Batch {batch_num} tentative {attempt+1}/3 : {batch_err}")
                        if attempt == 2:
                            logger.error(f"    âŒ Batch {batch_num} abandonnÃ© aprÃ¨s 3 tentatives")
                        import time; time.sleep(2 ** attempt)
                remaining = remaining[100:]
                batch_num += 1

            logger.info(f"  âœ… Notion page crÃ©Ã©e : {title} â†’ {url}")
            return url

        except Exception as e:
            logger.error(f"  âŒ Notion erreur ({title}) : {e}")
            return None

    # â”€â”€â”€ Notification Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def send_telegram_notification(self, notion_url: str, today: str) -> bool:
        """
        Envoie une notification courte sur Telegram avec le lien Notion.

        Analogie TP : Le SMS au maÃ®tre d'ouvrage "rapport dispo, voir classeur".
        """
        try:
            import telegram
            bot     = telegram.Bot(token=os.getenv("TELEGRAM_BOT_TOKEN"))
            chat_id = os.getenv("TELEGRAM_CHAT_ID")

            message = (
                f"ğŸ“‹ *VeilleurIA â€” {today}*\n\n"
                f"Ton rapport quotidien est prÃªt âœ…\n\n"
                f"ğŸ§  Agentique Â· ğŸ¦ OpenClaw Â· ğŸ› ï¸ Skills Claude\n\n"
                f"ğŸ‘‰ [Lire le rapport]({notion_url})"
                if notion_url else
                f"ğŸ“‹ *VeilleurIA â€” {today}*\n\nRapport gÃ©nÃ©rÃ© âœ… â€” consulte Notion."
            )

            await bot.send_message(chat_id=chat_id, text=message, parse_mode="Markdown")
            logger.info("  âœ… Notification Telegram envoyÃ©e")
            return True
        except Exception as e:
            logger.error(f"  âŒ Telegram : {e}")
            return False

    # â”€â”€â”€ Feedback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def save_feedback(self, fb_type: str, note: str) -> None:
        """Enregistre un feedback dans feedback_history.json."""
        existing = []
        if FEEDBACK_FILE.exists():
            with open(FEEDBACK_FILE, encoding="utf-8") as f:
                existing = json.load(f)
        existing.append({
            "type": fb_type, "note": note,
            "date": datetime.now().isoformat(),
            "report_date": datetime.now().strftime("%Y-%m-%d"),
        })
        with open(FEEDBACK_FILE, "w", encoding="utf-8") as f:
            json.dump(existing, f, ensure_ascii=False, indent=2)
        logger.info(f"  ğŸ’¾ Feedback '{fb_type}' : {note[:60]}")

    # â”€â”€â”€ Pipeline principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def run(self) -> int:
        """
        Pipeline complet v2.3 â€” 7 Ã©tapes.

        1. Collecte RSS     â†’ 10 sources + Reddit
        2. RÃ©sumÃ© RSS       â†’ Haiku Ã— 3 parties
        3. Recherche web    â†’ Sonnet 4.6 Ã— 12 requÃªtes
        4. Passe critique   â†’ Haiku Ã— 3 parties
        5. SynthÃ¨se rapport â†’ Sonnet 4.6 + Extended Thinking
        6. Redistribution   â†’ Notion Ã— 4 bases (Haiku extraction)
        7. Notification     â†’ Telegram avec lien Notion
        """
        if LOCK_FILE.exists() and not self.test_mode:
            logger.warning("âš ï¸  Lock file prÃ©sent â€” pipeline dÃ©jÃ  en cours ?")
            return 1

        try:
            LOCK_FILE.touch()
            today = datetime.now().strftime("%d/%m/%Y")
            logger.info("=" * 64)
            logger.info(f"ğŸš€ VeilleurIA v2.3 â€” {today} {datetime.now().strftime('%H:%M')}")
            logger.info(f"   {self.synthesis_model} | Thinking: {self.use_thinking}")
            logger.info("=" * 64)

            # â”€â”€ [1/7] Collecte RSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("ğŸ“¡ [1/7] Collecte RSS...")
            rss_agentique = self.collect_rss(RSS_AGENTIQUE)
            rss_openclaw  = self.collect_rss(RSS_OPENCLAW)
            rss_skills    = self.collect_rss(RSS_SKILLS_CLAUDE)

            # â”€â”€ [2/7] RÃ©sumÃ© RSS Haiku â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("âš¡ [2/7] RÃ©sumÃ© RSS via Haiku (3 parties)...")
            sum_agentique = self.summarize_rss(rss_agentique, "agentique")
            sum_openclaw  = self.summarize_rss(rss_openclaw,  "openclaw")
            sum_skills    = self.summarize_rss(rss_skills,    "skills Claude")

            # â”€â”€ [3/7] Recherche web Sonnet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("ğŸ” [3/7] Recherche web Sonnet 4.6 (12 requÃªtes)...")
            web_agentique = self.search_web(QUERIES_AGENTIQUE, "agentique")
            web_openclaw  = self.search_web(QUERIES_OPENCLAW,  "openclaw")
            web_skills    = self.search_web(QUERIES_SKILLS_CLAUDE, "skills Claude")

            # â”€â”€ [4/7] Passe critique Haiku â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("ğŸ¯ [4/7] Passe critique Haiku (3 parties)...")
            fil_agentique = self.critical_filter(sum_agentique, web_agentique, "agentique")
            fil_openclaw  = self.critical_filter(sum_openclaw,  web_openclaw,  "openclaw")
            fil_skills    = self.critical_filter(sum_skills,    web_skills,    "skills Claude")

            # â”€â”€ [5/7] SynthÃ¨se Sonnet 4.6 + Extended Thinking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("âœï¸  [5/7] SynthÃ¨se Sonnet 4.6 + Extended Thinking...")
            feedback = self.load_feedback()
            report   = self.generate_report(
                filtered_agentique = fil_agentique,
                filtered_openclaw  = fil_openclaw,
                filtered_skills    = fil_skills,
                feedback           = feedback,
            )

            # Archivage local
            report_path = Path(f"rapports/rapport_{datetime.now().strftime('%Y%m%d')}.md")
            report_path.parent.mkdir(exist_ok=True)
            report_path.write_text(report, encoding="utf-8")
            logger.info(f"  ğŸ’¾ Rapport archivÃ© : {report_path}")

            # Mode dry-run : affichage terminal uniquement, pas Notion/Telegram
            if self.dry_run:
                print("\n" + "=" * 64)
                print("ğŸ“‹ RAPPORT v2.3 (dry-run)")
                print("=" * 64)
                print(report)
                return 0

            # â”€â”€ [6/7] Redistribution Notion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("ğŸ“š [6/7] Redistribution vers Notion (4 bases)...")
            notion_rapport_url = None

            if NOTION_DB_RAPPORTS:
                notion_rapport_url = self.create_notion_page(
                    database_id = NOTION_DB_RAPPORTS,
                    title       = f"Veille IA â€” {today}",
                    content     = report,
                )
            if NOTION_DB_PEDAGOGIE:
                self.create_notion_page(
                    database_id = NOTION_DB_PEDAGOGIE,
                    title       = f"PÃ©dagogie â€” {today}",
                    content     = self.extract_for_notion(report, "pedagogie"),
                )
            if NOTION_DB_SYSTEME:
                self.create_notion_page(
                    database_id = NOTION_DB_SYSTEME,
                    title       = f"SystÃ¨me â€” {today}",
                    content     = self.extract_for_notion(report, "systeme"),
                )
            if NOTION_DB_MISE_EN_PLACE:
                self.create_notion_page(
                    database_id = NOTION_DB_MISE_EN_PLACE,
                    title       = f"Mise en place â€” {today}",
                    content     = self.extract_for_notion(report, "mise_en_place"),
                )

            # â”€â”€ [7/7] Notification Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.info("ğŸ“¤ [7/7] Notification Telegram...")
            asyncio.run(self.send_telegram_notification(
                notion_url = notion_rapport_url or "",
                today      = today,
            ))

            logger.info("âœ… Pipeline VeilleurIA v2.3 terminÃ© avec succÃ¨s")
            return 0

        except Exception as e:
            logger.error(f"âŒ Erreur pipeline : {e}", exc_info=True)
            return 1
        finally:
            if LOCK_FILE.exists():
                LOCK_FILE.unlink()


# â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main() -> int:
    parser = argparse.ArgumentParser(
        description="VeilleurIA v2.3 â€” Sonnet 4.6 + Notion + 3 parties",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples :
    python agent_veilleur_ia_v2_3.py                           # Production
    python agent_veilleur_ia_v2_3.py --test                    # Thinking off, rapide
    python agent_veilleur_ia_v2_3.py --dry-run                 # Terminal, pas Notion
    python agent_veilleur_ia_v2_3.py --feedback like "Super section Skills Claude"
        """,
    )
    parser.add_argument("--test",     action="store_true", help="Thinking off, rapide")
    parser.add_argument("--dry-run",  action="store_true", help="Rapport terminal, pas Notion/Telegram")
    parser.add_argument("--feedback", nargs=2, metavar=("TYPE", "NOTE"),
                        help="like | dislike | note 'texte'")
    args = parser.parse_args()

    if args.feedback:
        fb_type, fb_note = args.feedback
        if fb_type not in ("like", "dislike", "note"):
            print(f"âŒ Type invalide : {fb_type}")
            return 1
        agent = VeilleurIA(test_mode=True, dry_run=True)
        agent.save_feedback(fb_type, fb_note)
        print(f"âœ… Feedback '{fb_type}' : {fb_note}")
        return 0

    agent = VeilleurIA(test_mode=args.test, dry_run=args.dry_run)
    return agent.run()


if __name__ == "__main__":
    sys.exit(main())
