#!/usr/bin/env python3
"""
VeilleurIA v2.3 ‚Äî Agent de veille IA agentique avec hub Notion
==============================================================

Skill Claude natif ‚Äî API Anthropic (claude-sonnet-4-6).

NOUVEAUT√âS v2.3 vs v2.2 :

    ‚ë† Partie 3 ‚Äî Skills Claude
        Nouvelle section d√©di√©e aux skills Claude, MCP, et leur application
        directe √† la stack personnelle. Sous-section "Mise en place" qui
        fait le pont entre un concept p√©dagogique et son impl√©mentation
        concr√®te dans les skills existants.

    ‚ë° Reddit RSS ‚Äî 3 subreddits
        r/LocalLLaMA, r/AIAgents, r/MachineLearning ajout√©s comme sources
        RSS natives (sans API, feedparser suffit). Signal terrain qui
        compl√®te les blogs officiels.

    ‚ë¢ Hub Notion ‚Äî 4 destinations automatiques
        Sonnet g√©n√®re le rapport une seule fois.
        Haiku redistribue ensuite vers 4 bases Notion :
        - üìÖ Rapports quotidiens  (1 page compl√®te par jour)
        - üéì Base P√©dagogie       (1 entr√©e par concept, avec code color√©)
        - ‚öôÔ∏è  Base Syst√®me         (1 entr√©e par snippet production-ready)
        - üîó Mise en place        (1 entr√©e par action concr√®te identifi√©e)

    ‚ë£ Telegram ‚Äî notification courte
        Plus de rapport brut sur Telegram. Juste :
        "üìã Rapport du 18/02 pr√™t ‚Üí [lien Notion direct]"

Analogie TP :
    v2.2 = le topographe qui d√©pose son rapport sur le bureau
    v2.3 = le topographe qui d√©pose le rapport complet dans le classeur,
           extrait les cotes critiques dans le carnet de bord,
           colle les fiches techniques dans le cahier de r√©f√©rences,
           et envoie juste un SMS "rapport dispo, classeur bureau".

Architecture v2.3 :
    Cron 19h45
        ‚Üì
    [1] Collecte RSS ‚Üí Haiku (10 sources : 7 blogs + 3 Reddit)
        ‚Üì
    [2] Recherche web ‚Üí Sonnet 4.6 + web_search (12 requ√™tes : 3 parties)
        ‚Üì
    [3] Passe critique ‚Üí Haiku (filtre top 5 par partie, 3 parties)
        ‚Üì
    [4] Synth√®se rapport ‚Üí Sonnet 4.6 + Extended Thinking (3 parties)
        ‚Üì
    [5] Redistribution ‚Üí Haiku √ó 4 (extrait ‚Üí Notion bases d√©di√©es)
        ‚Üì
    [6] Notion API ‚Üí cr√©ation pages et entr√©es dans les 4 bases
        ‚Üì
    [7] Telegram ‚Üí notification courte avec lien Notion

Usage :
    python agent_veilleur_ia_v2_3.py              # Production compl√®te
    python agent_veilleur_ia_v2_3.py --test       # Haiku partout, thinking off
    python agent_veilleur_ia_v2_3.py --dry-run    # Rapport terminal, pas Notion/Telegram
    python agent_veilleur_ia_v2_3.py --feedback like "Super section Skills Claude"

Requirements :
    pip install anthropic feedparser python-telegram-bot python-dotenv tenacity notion-client

Author : Vlad / SRC ‚Äî Projet Agentic IA 2026
Version : 2.3.0
"""

import argparse
import json
import logging
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

import feedparser
from anthropic import Anthropic
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential

# ‚îÄ‚îÄ‚îÄ Logging ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("veilleur_ia.log", encoding="utf-8"),
    ],
)
logger = logging.getLogger(__name__)

load_dotenv()

# ‚îÄ‚îÄ‚îÄ Mod√®les ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Analogie TP : chef de chantier (Sonnet) et √©quipe terrain (Haiku)
MODEL_SYNTHESIS = "claude-sonnet-4-6"          # Synth√®se + Extended Thinking
MODEL_COLLECT   = "claude-haiku-4-5-20251001"  # Collecte, critique, redistribution

THINKING_BUDGET   = 3000   # Tokens de r√©flexion interne Sonnet 4.6
FEEDBACK_FILE     = Path("feedback_history.json")
LOCK_FILE         = Path("/tmp/veilleur_ia.lock")
FEEDBACK_WINDOW   = 14     # Jours de feedback inject√©s dans le prompt

# ‚îÄ‚îÄ‚îÄ Sources RSS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Blogs officiels ‚Äî Tier 1
RSS_AGENTIQUE = [
    {"name": "Anthropic Blog",  "url": "https://www.anthropic.com/rss.xml",      "focus": "agentique"},
    {"name": "LangChain Blog",  "url": "https://blog.langchain.dev/rss/",         "focus": "agentique"},
    {"name": "Hugging Face",    "url": "https://huggingface.co/papers.rss",       "focus": "agentique"},
    {"name": "The Rundown AI",  "url": "https://www.therundown.ai/feed",          "focus": "agentique"},
    {"name": "Latent Space",    "url": "https://www.latent.space/feed",           "focus": "agentique"},
    # ‚ë† NOUVEAU v2.3 ‚Äî Reddit RSS (sans API, feedparser natif)
    {"name": "r/LocalLLaMA",    "url": "https://www.reddit.com/r/LocalLLaMA/.rss",        "focus": "agentique"},
    {"name": "r/AIAgents",      "url": "https://www.reddit.com/r/AIAgents/.rss",          "focus": "agentique"},
    {"name": "r/MachineLearning","url": "https://www.reddit.com/r/MachineLearning/.rss",  "focus": "agentique"},
]

RSS_OPENCLAW = [
    {"name": "OpenClaw Releases",    "url": "https://github.com/openclaw/openclaw/releases.atom",    "focus": "openclaw"},
    {"name": "OpenClaw Discussions", "url": "https://github.com/openclaw/openclaw/discussions.atom", "focus": "openclaw"},
]

# ‚ë° NOUVEAU v2.3 ‚Äî Sources Skills Claude
RSS_SKILLS_CLAUDE = [
    {"name": "Anthropic Blog",       "url": "https://www.anthropic.com/rss.xml",      "focus": "skills"},
    {"name": "r/ClaudeAI",           "url": "https://www.reddit.com/r/ClaudeAI/.rss", "focus": "skills"},
]

# ‚îÄ‚îÄ‚îÄ Requ√™tes web_search ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 12 requ√™tes au total (4 par partie)

QUERIES_AGENTIQUE = [
    "agentic AI framework news today 2026",
    "LangGraph CrewAI AutoGen new release 2026",
    "Claude MCP A2A protocol update latest",
    "ArXiv agentic AI multi-agent paper today 2026",
    "LLM agent benchmark comparison 2026",
    "AI agent security vulnerability CVE 2026",
]

QUERIES_OPENCLAW = [
    "OpenClaw agent framework update 2026",
    "OpenClaw community discussion workflow hack",
    "ClawHub AgentSkill new release security 2026",
]

# ‚ë° NOUVEAU v2.3 ‚Äî Requ√™tes Skills Claude
QUERIES_SKILLS_CLAUDE = [
    "Claude skill MCP tool new release 2026",
    "Anthropic Claude API new feature update 2026",
    "Claude skill builder best practices production 2026",
]

# ‚îÄ‚îÄ‚îÄ IDs Notion (√† remplir apr√®s cr√©ation des pages) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Pour r√©cup√©rer un ID Notion : ouvrir la page ‚Üí "..." ‚Üí "Copy link"
# L'ID est la suite de chiffres/lettres √† la fin de l'URL (32 caract√®res)
NOTION_DB_RAPPORTS   = os.getenv("NOTION_DB_RAPPORTS_ID", "")    # üìÖ Rapports quotidiens
NOTION_DB_PEDAGOGIE  = os.getenv("NOTION_DB_PEDAGOGIE_ID", "")   # üéì Base P√©dagogie
NOTION_DB_SYSTEME    = os.getenv("NOTION_DB_SYSTEME_ID", "")     # ‚öôÔ∏è  Base Syst√®me
NOTION_DB_MISE_EN_PLACE = os.getenv("NOTION_DB_MISE_EN_PLACE_ID", "")  # üîó Mise en place


# ‚îÄ‚îÄ‚îÄ Classe principale ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class VeilleurIA:
    """
    Agent de veille IA agentique v2.3 ‚Äî Hub Notion + 3 parties.

    Analogie TP :
        L'√©quipe compl√®te de topographie + archivage :
        - Haiku = ouvriers collecte, tri, redistribution
        - Sonnet 4.6 + Thinking = chef de chantier qui r√©dige
        - Notion = le classeur de chantier structur√©
        - Telegram = le SMS de notification au ma√Ætre d'ouvrage
    """

    def __init__(self, test_mode: bool = False, dry_run: bool = False) -> None:
        self._check_env()
        self.client    = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.test_mode = test_mode
        self.dry_run   = dry_run

        # En mode test : Haiku pour collecte/redistribution, SONNET pour synth√®se
        # Haiku ne suit pas bien les prompts longs √† 3 parties
        self.synthesis_model = MODEL_SYNTHESIS  # Toujours Sonnet pour la synth√®se
        self.collect_model   = MODEL_COLLECT
        self.use_thinking    = not test_mode    # Thinking off en test pour aller vite

        # Client Notion ‚Äî initialis√© seulement si token disponible
        self.notion = self._init_notion()

        logger.info(
            f"üöÄ VeilleurIA v2.3 | {self.synthesis_model} | "
            f"Thinking: {self.use_thinking} | Notion: {'‚úÖ' if self.notion else '‚ùå'} | "
            f"Test: {test_mode} | DryRun: {dry_run}"
        )

    def _check_env(self) -> None:
        """V√©rifie les variables d'environnement obligatoires."""
        missing = [v for v in ["ANTHROPIC_API_KEY"] if not os.getenv(v)]
        if missing:
            raise EnvironmentError(f"‚ùå Variables manquantes : {', '.join(missing)}")

    def _init_notion(self):
        """
        Initialise le client Notion si le token est disponible.

        Analogie TP : V√©rifier qu'on a bien le badge d'acc√®s au classeur
        avant d'essayer de l'ouvrir.
        """
        token = os.getenv("NOTION_TOKEN")
        if not token:
            logger.warning("‚ö†Ô∏è  NOTION_TOKEN absent ‚Äî Notion d√©sactiv√©")
            return None
        try:
            from notion_client import Client
            client = Client(auth=token)
            logger.info("  ‚úÖ Client Notion initialis√©")
            return client
        except ImportError:
            logger.warning("‚ö†Ô∏è  notion-client non install√© ‚Üí pip install notion-client")
            return None
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Erreur init Notion : {e}")
            return None

    # ‚îÄ‚îÄ‚îÄ Collecte RSS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def collect_rss(self, sources: list[dict], max_hours: int = 24) -> list[dict]:
        """
        Collecte les entr√©es RSS des derni√®res N heures depuis toutes les sources.

        Analogie TP :
            Ramasser les feuilles de pointage de chaque corps de m√©tier
            d√©pos√©es depuis hier matin ‚Äî sans les lire, juste les ramasser.
        """
        entries = []
        cutoff  = datetime.now() - timedelta(hours=max_hours)

        for source in sources:
            try:
                logger.info(f"  üì° {source['name']}")
                feed = feedparser.parse(
                    source["url"],
                    # Header user-agent pour Reddit (bloque les bots sans header)
                    request_headers={"User-Agent": "VeilleurIA/2.3 (veille IA agentique)"}
                )
                for entry in feed.entries[:8]:
                    pub = None
                    if hasattr(entry, "published_parsed") and entry.published_parsed:
                        pub = datetime(*entry.published_parsed[:6])
                    if pub and pub < cutoff:
                        continue
                    entries.append({
                        "source":    source["name"],
                        "focus":     source["focus"],
                        "title":     entry.get("title", "Sans titre"),
                        "link":      entry.get("link", ""),
                        "summary":   entry.get("summary", "")[:400],
                        "published": pub.isoformat() if pub else "Inconnu",
                    })
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è  RSS {source['name']} : {e}")

        logger.info(f"  ‚úÖ {len(entries)} entr√©es collect√©es")
        return entries

    # ‚îÄ‚îÄ‚îÄ R√©sum√© RSS Haiku ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def summarize_rss(self, entries: list[dict], focus: str) -> str:
        """
        R√©sume les entr√©es RSS brutes via Haiku (d√©blaiement m√©canique).

        Analogie TP :
            L'ouvrier qui retranscrit les cotes brutes sur son carnet :
            travail m√©canique, pas de jugement requis.
        """
        if not entries:
            return f"Aucune entr√©e RSS r√©cente pour {focus}."

        formatted = "\n".join(
            f"- [{e['source']}] {e['title']}\n  {e['summary']}"
            for e in entries[:12]
        )
        response = self.client.messages.create(
            model=self.collect_model,
            max_tokens=600,
            messages=[{"role": "user", "content":
                f"R√©sume en 3-5 points cl√©s factuels les infos RSS {focus} :\n\n{formatted}"
            }],
        )
        return response.content[0].text

    # ‚îÄ‚îÄ‚îÄ Recherche web Sonnet 4.6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def search_web(self, queries: list[str], focus: str) -> str:
        """
        Recherche web via Sonnet 4.6 + outil web_search natif.

        Analogie TP :
            Le topographe senior avec sa station totale : il fait ses propres
            relev√©s terrain, ne se contente pas de copier les plans existants.
        """
        logger.info(f"  üîç {len(queries)} requ√™tes web ({focus})")
        queries_fmt = "\n".join(f"{i+1}. {q}" for i, q in enumerate(queries))
        response = self.client.messages.create(
            model=self.synthesis_model,
            max_tokens=2500,
            tools=[{"type": "web_search_20250305", "name": "web_search"}],
            messages=[{"role": "user", "content":
                f"""Expert IA agentique, veille quotidienne {focus} ‚Äî {datetime.now().strftime('%d/%m/%Y')}.
Lance ces recherches et synth√©tise les r√©sultats factuellement :
{queries_fmt}
Identifie : annonces majeures, releases, discussions importantes, sources (URLs)."""
            }],
        )
        return "".join(b.text for b in response.content if hasattr(b, "text")) or "Aucun r√©sultat."

    # ‚îÄ‚îÄ‚îÄ Passe critique Haiku ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def critical_filter(self, rss: str, web: str, focus: str) -> str:
        """
        Filtre Haiku : extrait le top 5 informations les plus importantes.

        Analogie TP :
            Avant de pr√©senter au ma√Ætre d'ouvrage, l'assistant trie les
            50 relev√©s et ne garde que les 5 cotes critiques pour la d√©cision.
        """
        logger.info(f"  üéØ Passe critique ({focus})")
        response = self.client.messages.create(
            model=self.collect_model,
            max_tokens=500,
            messages=[{"role": "user", "content":
                f"""√âditeur expert IA {focus}. Identifie les 5 infos les PLUS IMPORTANTES du jour.

RSS : {rss}
WEB : {web}

Crit√®res : nouveaut√© r√©elle, impact praticien IA, actionnable, pas de doublon.
Format : 1. [SOURCE] Titre ‚Äî impact en une phrase (5 max, tri√©s par importance)"""
            }],
        )
        return response.content[0].text

    # ‚îÄ‚îÄ‚îÄ Chargement feedback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def load_feedback(self) -> str:
        """Charge le contexte feedback des 14 derniers jours."""
        if not FEEDBACK_FILE.exists():
            return "Aucun feedback historique."
        try:
            with open(FEEDBACK_FILE, encoding="utf-8") as f:
                all_fb = json.load(f)
            cutoff = datetime.now() - timedelta(days=FEEDBACK_WINDOW)
            recent = [fb for fb in all_fb if datetime.fromisoformat(fb["date"]) > cutoff]
            if not recent:
                return "Aucun feedback r√©cent."
            likes    = [fb["note"] for fb in recent if fb["type"] == "like"]
            dislikes = [fb["note"] for fb in recent if fb["type"] == "dislike"]
            notes    = [fb["note"] for fb in recent if fb["type"] == "note"]
            return f"""FEEDBACK 14 DERNIERS JOURS ({len(recent)} retours) :
‚úÖ Appr√©ci√© : {chr(10).join(f'- {l}' for l in likes[-5:]) if likes else '- Aucun encore'}
‚ùå Pas plu : {chr(10).join(f'- {d}' for d in dislikes[-5:]) if dislikes else '- Aucun encore'}
üìù Notes : {chr(10).join(f'- {n}' for n in notes[-3:]) if notes else '- Aucune encore'}
‚Üí Adapte le rapport selon ces pr√©f√©rences."""
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Feedback : {e}")
            return "Erreur chargement feedback."

    # ‚îÄ‚îÄ‚îÄ Synth√®se rapport Sonnet 4.6 + Extended Thinking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def generate_report(
        self,
        filtered_agentique:   str,
        filtered_openclaw:    str,
        filtered_skills:      str,
        feedback:             str,
    ) -> str:
        """
        G√©n√®re le rapport complet via Sonnet 4.6 + Extended Thinking.

        Analogie TP :
            Le conducteur de travaux qui s'assoit 10 minutes avec ses notes
            (Extended Thinking), r√©fl√©chit aux connexions entre les 3 chantiers,
            puis r√©dige le compte-rendu ma√Ætre d'ouvrage d'une traite.

        Structure rapport v2.3 : 3 parties √ó (Info + P√©dagogie + Syst√®me + Mise en place)
        Cible : 6000-7000 mots au total.
        """
        today = datetime.now().strftime("%d/%m/%Y")

        prompt = f"""Tu es VeilleurIA v2.3, expert IA agentique. Rapport quotidien pour Vlad.

PROFIL : Conducteur de travaux TP ‚Üí reconversion ing√©nieur IA agentique.
CS50P valid√© + 275p ML + stack 13 agents en prod. Praticien, pas th√©oricien.

{feedback}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
TOP INFOS DU JOUR ‚Äî {today}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üß† AGENTIQUE (top 5) : {filtered_agentique}
ü¶û OPENCLAW (top 5)  : {filtered_openclaw}
üõ†Ô∏è  SKILLS CLAUDE (top 5) : {filtered_skills}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
FORMAT RAPPORT ‚Äî EXIGENCES STRICTES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

G√©n√®re EXACTEMENT ce format. Cible : 6000-7000 mots.

---
ü§ñ VEILLE IA AGENTIQUE ‚Äî {today}
---

## üß† PARTIE 1 : AGENTIQUE G√âN√âRALE

### üì∞ Information (200-250 mots)
2-3 news majeures : faits + pourquoi important maintenant + impact concret pour Vlad.

### üéì P√©dagogie (400-500 mots)
Structure OBLIGATOIRE :
**Concept** : d√©finition claire
**Analogie BTP** : cas concret chantier/TP
**M√©canisme** : comment √ßa marche sous le capot
**Code** : bloc Python 15-25 lignes, commentaires PAR BLOC (pas ligne par ligne)
**Impact stack** : connexion directe stack V1.0 ou use case SRC
**Ressources** : 1-2 liens concrets

### ‚öôÔ∏è Syst√®me (500-600 mots)
Config ou snippet COMPLET production-ready :
**Architecture** : sch√©ma ASCII si pertinent
**Code production-ready** : complet, comment√© par bloc, gestion erreurs
**Commandes exactes** : shell/CLI dans l'ordre
**Param√®tres critiques** : valeurs, pi√®ges, defaults dangereux
**Int√©gration V1.0** : comment brancher sur le Makefile/agents.yaml existant

### üîó Mise en place (200-300 mots)
Bridge p√©dagogie ‚Üí action concr√®te :
**Ce concept s'applique √†** : quel skill existant de Vlad (VeilleurIA, Sheriff, Coder...)
**3 √©tapes concr√®tes** : num√©rot√©es, actionnables d√®s demain
**Commande de test** : valider que c'est en place

---

## ü¶û PARTIE 2 : OPENCLAW

### üì∞ Information (200-250 mots)
Releases (num√©ro version exact), breaking changes, nouvelles features, CVE si applicable.

### üéì P√©dagogie (400-500 mots)
Structure OBLIGATOIRE :
**Concept OpenClaw** : ce que c'est, pourquoi dans OpenClaw
**Analogie BTP** : OPC, sous-traitants, etc.
**M√©canisme** : agents.yaml, gateway, skills
**Config YAML** : bloc complet comment√© par bloc, production-ready
**Cas usage Vlad** : avec VeilleurIA ou stack V1.0
**Commande d√©ploiement** : commande exacte openclaw

### ‚öôÔ∏è Syst√®me (500-600 mots)
AgentSkill ou workflow communautaire :
**Config YAML compl√®te** : comment√©e par bloc
**Hack communautaire** : technique + contexte
**Int√©gration KVM1** : comment brancher sur le gateway Hostinger
**Snippet Python** : si applicable, production-ready
**Test validation** : commande pour v√©rifier avant push prod

### üîó Mise en place (200-300 mots)
**S'applique √†** : quel composant OpenClaw de la stack Vlad
**3 √©tapes** : actionnables d√®s demain
**Commande de test** : validation concr√®te

---

## üõ†Ô∏è PARTIE 3 : SKILLS CLAUDE

### üì∞ Information (200-250 mots)
Nouveaux skills, mises √† jour MCP, √©volutions API Claude, discussions communautaires.

### üéì P√©dagogie (400-500 mots)
Structure OBLIGATOIRE :
**Concept skill** : ce qu'est ce skill/feature, pourquoi il existe
**Analogie BTP** : connexion terrain TP
**M√©canisme** : comment Claude l'impl√©mente (system prompt, tools, context)
**Exemple config** : YAML ou Python complet, comment√© par bloc
**Application VeilleurIA** : comment am√©liorer VeilleurIA avec ce concept
**Ressources** : doc Anthropic, exemples GitHub

### ‚öôÔ∏è Syst√®me (500-600 mots)
Skill production-ready :
**Config compl√®te** : YAML ou Python, comment√©e par bloc
**Int√©gration stack** : comment brancher sur les agents existants
**Param√®tres cl√©s** : ce qui change vraiment la qualit√©
**Test validation** : comment v√©rifier que le skill fonctionne bien
**Optimisation co√ªt** : si applicable, model routing intelligent

### üîó Mise en place (200-300 mots)
**S'applique directement √†** : VeilleurIA v2.3 ou skill sp√©cifique existant
**3 √©tapes concr√®tes** : num√©rot√©es, avec commandes si applicable
**Validation** : comment mesurer que l'am√©lioration est effective

---

## üí° INSIGHT DU JOUR (150-200 mots)
Connexion transversale non √©vidente entre les 3 parties.
Tendance de fond. Implication strat√©gique pour Vlad.
Pas une conclusion g√©n√©rique ‚Äî un vrai insight.

---
üìä Sources : [liste cl√©s avec URLs]
‚è±Ô∏è {datetime.now().strftime("%H:%M")} | VeilleurIA v2.3 | Sonnet 4.6 + Extended Thinking
---

R√àGLES ABSOLUES :
- Code comment√© PAR BLOC (pas ligne par ligne, pas sans commentaires)
- Analogies BTP syst√©matiques dans toutes les sections P√©dagogie
- Snippets directement int√©grables dans la stack V1.0
- Jamais inventer une info ‚Äî absence > inexactitude
- Si section vide aujourd'hui : d√©velopper les autres"""

        params: dict = {
            "model":      self.synthesis_model,
            "max_tokens": 14000,  # thinking (3000) + output 7000 mots (~9000 tokens) + marge
            "messages":   [{"role": "user", "content": prompt}],
        }
        if self.use_thinking:
            params["thinking"] = {"type": "enabled", "budget_tokens": THINKING_BUDGET}
            logger.info(f"  üß† Extended Thinking activ√© ({THINKING_BUDGET} tokens budget)")

        response = self.client.messages.create(**params)

        # Extraire uniquement le texte final (pas les blocs thinking internes)
        report = "".join(
            b.text for b in response.content
            if hasattr(b, "type") and b.type == "text"
        )
        return report or "Erreur g√©n√©ration rapport."

    # ‚îÄ‚îÄ‚îÄ Redistribution Notion via Haiku ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(min=2, max=10))
    def extract_for_notion(self, report: str, section: str) -> str:
        """
        Haiku extrait une section sp√©cifique du rapport pour Notion.

        Analogie TP :
            L'assistant qui photocopie uniquement les pages pertinentes
            du rapport complet pour les classer dans les bons classeurs.

        Args:
            report  : Rapport complet g√©n√©r√© par Sonnet
            section : "pedagogie", "systeme" ou "mise_en_place"

        Returns:
            Contenu extrait et format√© pour Notion
        """
        instructions = {
            "pedagogie": """Extrais UNIQUEMENT toutes les sections üéì P√©dagogie des 3 parties.
Format : ## Partie X ‚Äî [Titre concept]\n[contenu p√©dagogie]\n\n""",
            "systeme": """Extrais UNIQUEMENT toutes les sections ‚öôÔ∏è Syst√®me des 3 parties.
Garde tous les blocs de code intacts avec leur syntaxe.
Format : ## Partie X ‚Äî [Titre]\n[contenu syst√®me avec code]\n\n""",
            "mise_en_place": """Extrais UNIQUEMENT toutes les sections üîó Mise en place des 3 parties.
Format : ## Partie X ‚Äî [Skill/composant cibl√©]\n[3 √©tapes + commande test]\n\n""",
        }

        response = self.client.messages.create(
            model=self.collect_model,
            max_tokens=6000,
            messages=[{"role": "user", "content":
                f"{instructions[section]}\n\nRAPPORT COMPLET :\n{report[:40000]}"
            }],
        )
        return response.content[0].text

    # ‚îÄ‚îÄ‚îÄ Cr√©ation page Notion ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def _parse_content_to_blocks(self, content: str) -> list:
        """
        Parse le contenu Markdown en blocs Notion proprement.

        Analogie TP :
            Trier les mat√©riaux avant de les ranger : b√©ton avec b√©ton,
            ferraillage avec ferraillage. On ne m√©lange pas les types.

        Le probl√®me du split na√Øf sur '\\n\\n' :
            Un bloc ```python\\ncode\\n``` contient des sauts de ligne
            internes ‚Üí le split le d√©coupe en morceaux inutilisables.
        Solution : on parse ligne par ligne avec un √©tat (dans/hors code).
        """
        blocks = []
        lines = content.split("\n")
        i = 0

        while i < len(lines):
            line = lines[i]

            # ‚îÄ‚îÄ Bloc de code : on accumule jusqu'au ``` fermant ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if line.strip().startswith("```"):
                lang = line.strip().replace("```", "").strip() or "python"
                code_lines = []
                i += 1
                while i < len(lines) and not lines[i].strip().startswith("```"):
                    code_lines.append(lines[i])
                    i += 1
                code = "\n".join(code_lines).strip()
                if code:
                    # D√©coupe si > 1990 chars (limite Notion par bloc)
                    for chunk in [code[j:j+1990] for j in range(0, len(code), 1990)]:
                        blocks.append({
                            "object": "block",
                            "type":   "code",
                            "code": {
                                "rich_text": [{"type": "text", "text": {"content": chunk}}],
                                "language":  lang if lang in [
                                    "python", "javascript", "bash", "yaml",
                                    "json", "markdown", "plain text"
                                ] else "plain text",
                            },
                        })
                i += 1  # saute le ``` fermant
                continue

            # ‚îÄ‚îÄ Titre niveau 1 (#) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if line.startswith("# ") and not line.startswith("## "):
                blocks.append({
                    "object": "block", "type": "heading_1",
                    "heading_1": {"rich_text": [{"type": "text", "text": {
                        "content": line.replace("# ", "")[:200]
                    }}]},
                })
                i += 1
                continue

            # ‚îÄ‚îÄ Titre niveau 2 (##) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if line.startswith("## "):
                blocks.append({
                    "object": "block", "type": "heading_2",
                    "heading_2": {"rich_text": [{"type": "text", "text": {
                        "content": line.replace("## ", "")[:200]
                    }}]},
                })
                i += 1
                continue

            # ‚îÄ‚îÄ Titre niveau 3 (###) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if line.startswith("### "):
                blocks.append({
                    "object": "block", "type": "heading_3",
                    "heading_3": {"rich_text": [{"type": "text", "text": {
                        "content": line.replace("### ", "")[:200]
                    }}]},
                })
                i += 1
                continue

            # ‚îÄ‚îÄ Ligne vide ‚Üí on skippe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if not line.strip():
                i += 1
                continue

            # ‚îÄ‚îÄ Paragraphe standard ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            for chunk in [line[j:j+1990] for j in range(0, len(line), 1990)]:
                blocks.append({
                    "object": "block", "type": "paragraph",
                    "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]},
                })
            i += 1

        return blocks

    def create_notion_page(
        self,
        database_id: str,
        title:       str,
        content:     str,
        categorie:   Optional[str] = None,
    ) -> Optional[str]:
        """
        Cr√©e une sous-page dans une page Notion parente.

        Analogie TP :
            Ajouter une feuille dans le bon classeur avec le bon onglet.

        Args:
            database_id : ID de la page Notion parente
            title       : Titre de la page
            content     : Contenu Markdown √† ins√©rer
            categorie   : Non utilis√© (pages simples)

        Returns:
            URL de la page cr√©√©e, ou None si erreur
        """
        if not self.notion or not database_id:
            logger.warning(f"  ‚ö†Ô∏è  Notion non disponible pour '{title}'")
            return None

        try:
            # D√©coupage du contenu en blocs Notion
            content_blocks = []
            for paragraph in content.split("\n\n"):
                if not paragraph.strip():
                    continue
                # Bloc code si commence par ```
                if paragraph.strip().startswith("```"):
                    lang = paragraph.split("\n")[0].replace("```", "").strip() or "python"
                    code = "\n".join(paragraph.split("\n")[1:]).rstrip("`").strip()
                    content_blocks.append({
                        "object": "block",
                        "type":   "code",
                        "code":   {
                            "rich_text": [{"type": "text", "text": {"content": code[:1990]}}],
                            "language":  lang,
                        },
                    })
                elif paragraph.startswith("## "):
                    content_blocks.append({
                        "object": "block",
                        "type":   "heading_2",
                        "heading_2": {
                            "rich_text": [{"type": "text", "text": {
                                "content": paragraph.replace("## ", "")[:200]
                            }}]
                        },
                    })
                elif paragraph.startswith("### "):
                    content_blocks.append({
                        "object": "block",
                        "type":   "heading_3",
                        "heading_3": {
                            "rich_text": [{"type": "text", "text": {
                                "content": paragraph.replace("### ", "")[:200]
                            }}]
                        },
                    })
                else:
                    for chunk in [paragraph[i:i+1990] for i in range(0, len(paragraph), 1990)]:
                        content_blocks.append({
                            "object": "block",
                            "type":   "paragraph",
                            "paragraph": {
                                "rich_text": [{"type": "text", "text": {"content": chunk}}]
                            },
                        })

            # Cr√©ation sous-page avec parent = page_id (pas database_id)
            page = self.notion.pages.create(
                parent={"page_id": database_id},
                properties={
                    "title": {"title": [{"text": {"content": title}}]}
                },
                children=self._parse_content_to_blocks(content)[:100],
            )
            url = page.get("url", "")
            logger.info(f"  ‚úÖ Notion page cr√©√©e : {title} ‚Üí {url}")
            return url

        except Exception as e:
            logger.error(f"  ‚ùå Notion erreur ({title}) : {e}")
            return None

    # ‚îÄ‚îÄ‚îÄ Envoi notification Telegram ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def send_telegram_notification(self, notion_url: str, today: str) -> bool:
        """
        Envoie une notification courte sur Telegram avec le lien Notion.

        Analogie TP :
            Le SMS au ma√Ætre d'ouvrage : "Rapport chantier dispo, voir classeur bureau."
            Pas le rapport complet par SMS ‚Äî juste la notification.
        """
        try:
            import telegram
            bot     = telegram.Bot(token=os.getenv("TELEGRAM_BOT_TOKEN"))
            chat_id = os.getenv("TELEGRAM_CHAT_ID")

            # Message court et lisible ‚Äî le rapport est sur Notion
            message = (
                f"üìã *VeilleurIA ‚Äî {today}*\n\n"
                f"Ton rapport quotidien est pr√™t ‚úÖ\n\n"
                f"üß† Agentique ¬∑ ü¶û OpenClaw ¬∑ üõ†Ô∏è Skills Claude\n\n"
                f"üëâ [Lire le rapport]({notion_url})"
                if notion_url else
                f"üìã *VeilleurIA ‚Äî {today}*\n\n"
                f"Rapport g√©n√©r√© ‚úÖ ‚Äî consulte Notion pour le lire."
            )

            await bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode="Markdown",
            )
            logger.info("  ‚úÖ Notification Telegram envoy√©e")
            return True
        except Exception as e:
            logger.error(f"  ‚ùå Telegram : {e}")
            return False

    # ‚îÄ‚îÄ‚îÄ Feedback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def save_feedback(self, fb_type: str, note: str) -> None:
        """Enregistre un feedback dans feedback_history.json."""
        existing = []
        if FEEDBACK_FILE.exists():
            with open(FEEDBACK_FILE, encoding="utf-8") as f:
                existing = json.load(f)
        existing.append({
            "type": fb_type, "note": note,
            "date": datetime.now().isoformat(),
            "report_date": datetime.now().strftime("%Y-%m-%d"),
        })
        with open(FEEDBACK_FILE, "w", encoding="utf-8") as f:
            json.dump(existing, f, ensure_ascii=False, indent=2)
        logger.info(f"  üíæ Feedback '{fb_type}' : {note[:60]}")

    # ‚îÄ‚îÄ‚îÄ Pipeline principal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    def run(self) -> int:
        """
        Pipeline complet v2.3 ‚Äî 7 √©tapes.

        √âtapes :
            1. Collecte RSS (10 sources + 2 Skills Claude)
            2. R√©sum√© brut RSS √ó 3 parties (Haiku)
            3. Recherche web 12 requ√™tes √ó 3 parties (Sonnet 4.6)
            4. Passe critique √ó 3 parties (Haiku)
            5. Synth√®se rapport 3 parties (Sonnet 4.6 + Extended Thinking)
            6. Redistribution Notion √ó 4 bases (Haiku)
            7. Notification Telegram (lien Notion)
        """
        if LOCK_FILE.exists() and not self.test_mode:
            logger.warning("‚ö†Ô∏è  Lock file pr√©sent ‚Äî pipeline d√©j√† en cours ?")
            return 1

        try:
            LOCK_FILE.touch()
            today = datetime.now().strftime("%d/%m/%Y")
            logger.info("=" * 64)
            logger.info(f"üöÄ VeilleurIA v2.3 ‚Äî {today} {datetime.now().strftime('%H:%M')}")
            logger.info(f"   {self.synthesis_model} | Thinking: {self.use_thinking}")
            logger.info("=" * 64)

            # ‚îÄ‚îÄ [1/7] Collecte RSS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("üì° [1/7] Collecte RSS (10 sources + Reddit)...")
            rss_agentique = self.collect_rss(RSS_AGENTIQUE)
            rss_openclaw  = self.collect_rss(RSS_OPENCLAW)
            rss_skills    = self.collect_rss(RSS_SKILLS_CLAUDE)

            # ‚îÄ‚îÄ [2/7] R√©sum√© RSS Haiku ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("‚ö° [2/7] R√©sum√© RSS via Haiku (3 parties)...")
            sum_agentique = self.summarize_rss(rss_agentique, "agentique")
            sum_openclaw  = self.summarize_rss(rss_openclaw,  "openclaw")
            sum_skills    = self.summarize_rss(rss_skills,    "skills Claude")

            # ‚îÄ‚îÄ [3/7] Recherche web Sonnet ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("üîç [3/7] Recherche web Sonnet 4.6 (12 requ√™tes)...")
            web_agentique = self.search_web(QUERIES_AGENTIQUE, "agentique")
            web_openclaw  = self.search_web(QUERIES_OPENCLAW,  "openclaw")
            web_skills    = self.search_web(QUERIES_SKILLS_CLAUDE, "skills Claude")

            # ‚îÄ‚îÄ [4/7] Passe critique Haiku ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("üéØ [4/7] Passe critique Haiku (3 parties)...")
            fil_agentique = self.critical_filter(sum_agentique, web_agentique, "agentique")
            fil_openclaw  = self.critical_filter(sum_openclaw,  web_openclaw,  "openclaw")
            fil_skills    = self.critical_filter(sum_skills,    web_skills,    "skills Claude")

            # ‚îÄ‚îÄ [5/7] Synth√®se Sonnet 4.6 + Extended Thinking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("‚úçÔ∏è  [5/7] Synth√®se Sonnet 4.6 + Extended Thinking...")
            feedback = self.load_feedback()
            report   = self.generate_report(
                filtered_agentique = fil_agentique,
                filtered_openclaw  = fil_openclaw,
                filtered_skills    = fil_skills,
                feedback           = feedback,
            )

            # Archivage local toujours
            report_path = Path(f"rapports/rapport_{datetime.now().strftime('%Y%m%d')}.md")
            report_path.parent.mkdir(exist_ok=True)
            report_path.write_text(report, encoding="utf-8")
            logger.info(f"  üíæ Rapport archiv√© localement : {report_path}")

            # Mode dry-run : affichage terminal uniquement
            if self.dry_run:
                print("\n" + "=" * 64)
                print("üìã RAPPORT v2.3 (dry-run ‚Äî Notion et Telegram d√©sactiv√©s)")
                print("=" * 64)
                print(report)
                print("=" * 64)
                return 0

            # ‚îÄ‚îÄ [6/7] Redistribution Notion ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("üìö [6/7] Redistribution vers Notion (4 bases)...")
            notion_rapport_url = None

            # Base Rapports ‚Äî rapport complet
            if NOTION_DB_RAPPORTS:
                notion_rapport_url = self.create_notion_page(
                    database_id = NOTION_DB_RAPPORTS,
                    title       = f"Veille IA ‚Äî {today}",
                    content     = report,
                )

            # Extraction et insertion P√©dagogie
            if NOTION_DB_PEDAGOGIE:
                pedagogie_content = self.extract_for_notion(report, "pedagogie")
                self.create_notion_page(
                    database_id = NOTION_DB_PEDAGOGIE,
                    title       = f"P√©dagogie ‚Äî {today}",
                    content     = pedagogie_content,
                )

            # Extraction et insertion Syst√®me
            if NOTION_DB_SYSTEME:
                systeme_content = self.extract_for_notion(report, "systeme")
                self.create_notion_page(
                    database_id = NOTION_DB_SYSTEME,
                    title       = f"Syst√®me ‚Äî {today}",
                    content     = systeme_content,
                )

            # Extraction et insertion Mise en place
            if NOTION_DB_MISE_EN_PLACE:
                mep_content = self.extract_for_notion(report, "mise_en_place")
                self.create_notion_page(
                    database_id = NOTION_DB_MISE_EN_PLACE,
                    title       = f"Mise en place ‚Äî {today}",
                    content     = mep_content,
                )

            # ‚îÄ‚îÄ [7/7] Notification Telegram ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            logger.info("üì§ [7/7] Notification Telegram...")
            import asyncio
            asyncio.run(self.send_telegram_notification(
                notion_url = notion_rapport_url or "",
                today      = today,
            ))

            logger.info("‚úÖ Pipeline VeilleurIA v2.3 termin√© avec succ√®s")
            return 0

        except Exception as e:
            logger.error(f"‚ùå Erreur pipeline : {e}", exc_info=True)
            return 1
        finally:
            if LOCK_FILE.exists():
                LOCK_FILE.unlink()


# ‚îÄ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main() -> int:
    parser = argparse.ArgumentParser(
        description="VeilleurIA v2.3 ‚Äî Sonnet 4.6 + Notion + 3 parties",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples :
    python agent_veilleur_ia_v2_3.py                         # Production
    python agent_veilleur_ia_v2_3.py --test                  # Haiku partout, rapide
    python agent_veilleur_ia_v2_3.py --dry-run               # Terminal, pas Notion
    python agent_veilleur_ia_v2_3.py --feedback like "Super section Skills Claude"
        """,
    )
    parser.add_argument("--test",    action="store_true", help="Haiku partout, thinking off")
    parser.add_argument("--dry-run", action="store_true", help="Rapport terminal, pas Notion/Telegram")
    parser.add_argument("--feedback", nargs=2, metavar=("TYPE", "NOTE"),
                        help="like | dislike | note 'texte'")
    args = parser.parse_args()

    if args.feedback:
        fb_type, fb_note = args.feedback
        if fb_type not in ("like", "dislike", "note"):
            print(f"‚ùå Type invalide : {fb_type}")
            return 1
        agent = VeilleurIA(test_mode=True, dry_run=True)
        agent.save_feedback(fb_type, fb_note)
        print(f"‚úÖ Feedback '{fb_type}' : {fb_note}")
        return 0

    agent = VeilleurIA(test_mode=args.test, dry_run=args.dry_run)
    return agent.run()


if __name__ == "__main__":
    sys.exit(main())
